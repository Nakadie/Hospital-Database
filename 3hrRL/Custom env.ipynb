{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57927d00",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111e77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gym imports\n",
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "# Helper imports\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# import stable baselines stuff\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c97e1c5",
   "metadata": {},
   "source": [
    "# 2. Types of Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c87606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used for discrete number of actions but want only 1\n",
    "Discrete(3).sample() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e82dd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6468273 , 0.98046225, 0.9102171 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# continuous variables, upper, lower, then shape\n",
    "Box(0,1, shape=(3,)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536a2cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, array([0.4788525 , 0.50169337, 0.5556536 ], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#currently not supported by gym\n",
    "Tuple((Discrete(3), Box(0,1, shape=(3,)))).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33fe2e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('height', 0), ('speed', array([85.525375], dtype=float32))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different types of spaces pass through\n",
    "Dict({'height': Discrete(2), 'speed': Box(0,100, shape=(1,))}).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae75c00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#could add to tuple, or dict, number of positions and only 0,1 result\n",
    "MultiBinary(4).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dac5cf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "MultiDiscrete([5,2,2]).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a33f0",
   "metadata": {},
   "source": [
    "# 3. Building an Env\n",
    "- build an agent to give us the best shower possible\n",
    "- random temp\n",
    "- 37 and 39 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19a1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        # Actions we can take, down, stay, up\n",
    "        self.action_space = Discrete(3)\n",
    "        # Temperature array\n",
    "        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
    "        # Set start temp\n",
    "        self.state = 38 + random.randint(-3,3)\n",
    "        # Set shower length\n",
    "        self.shower_length = 60\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Apply action\n",
    "        # 0 -1 = -1 temperature\n",
    "        # 1 -1 = 0 \n",
    "        # 2 -1 = 1 temperature \n",
    "        self.state += action -1 \n",
    "        # Reduce shower length by 1 second\n",
    "        self.shower_length -= 1 \n",
    "        \n",
    "        # Calculate reward\n",
    "        if self.state >=37 and self.state <=39: \n",
    "            reward =1 \n",
    "        else: \n",
    "            reward = -1 \n",
    "        \n",
    "        # Check if shower is done\n",
    "        if self.shower_length <= 0: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # Apply temperature noise\n",
    "        #self.state += random.randint(-1,1)\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset shower temperature\n",
    "        self.state = np.array([38 + random.randint(-3,3)]).astype(float)\n",
    "        # Reset shower time\n",
    "        self.shower_length = 60 \n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08b39f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kamuela\\anaconda3\\envs\\RLin3hr\\lib\\site-packages\\gym\\logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "env = ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6cca96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([0.], [100.], (1,), float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b720156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9138f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ca4eb6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The observation returned by the `reset()` method does not match the given observation space",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16300/1913415460.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcheck_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\RLin3hr\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py\u001b[0m in \u001b[0;36mcheck_env\u001b[1;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;31m# ============ Check the returned values ===============\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m     \u001b[0m_check_returned_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;31m# ==== Check the render method and the declared render modes ====\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RLin3hr\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py\u001b[0m in \u001b[0;36m_check_returned_values\u001b[1;34m(env, observation_space, action_space)\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Error while checking key={key}: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0m_check_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"reset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;31m# Sample a random action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RLin3hr\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py\u001b[0m in \u001b[0;36m_check_obs\u001b[1;34m(obs, observation_space, method_name)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"The observation returned by `{method_name}()` method must be a numpy array\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     assert observation_space.contains(\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     ), f\"The observation returned by the `{method_name}()` method does not match the given observation space\"\n",
      "\u001b[1;31mAssertionError\u001b[0m: The observation returned by the `reset()` method does not match the given observation space"
     ]
    }
   ],
   "source": [
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8647ad79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-20\n",
      "Episode:2 Score:-60\n",
      "Episode:3 Score:-40\n",
      "Episode:4 Score:-42\n",
      "Episode:5 Score:16\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode,score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d9c63f",
   "metadata": {},
   "source": [
    "# 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5354da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "792e58fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_9\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -37.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 462      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -37.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 611        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00823976 |\n",
      "|    clip_fraction        | 0.0777     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0.000191   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 18.2       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.00431   |\n",
      "|    value_loss           | 44.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -36.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 680         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012819884 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.000136    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -33.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 723          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021200904 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 5.48e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | 0.000143     |\n",
      "|    value_loss           | 68.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -28.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 754          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082191415 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 1e-05        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.5         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    value_loss           | 76.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -29.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 775         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006585217 |\n",
      "|    clip_fraction        | 0.0406      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -6.81e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    value_loss           | 79.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -26.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 790         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009231221 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 7.67e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    value_loss           | 67.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -27.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 800         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013826985 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -9.04e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    value_loss           | 76.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -24.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 810         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005056249 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.00345    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    value_loss           | 71.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -25.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 821          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055887783 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -0.00126     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 46           |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    value_loss           | 84.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1eaa00a91c0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps = 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069338e2",
   "metadata": {},
   "source": [
    "# 6. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510e6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join('Training', 'Saved Models', 'Shower_Model_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cfb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(ppo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9063e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11eb9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(ppo_path, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c78b48b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16300/2917599890.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_eval_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05a6cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLin3hr",
   "language": "python",
   "name": "rlin3hr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
